# =========================================================
# IMPORTS
# =========================================================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st

# =========================================================
# UTILS
# =========================================================

def tenor_to_years(col):
    t = col.split("_")[-1].upper()
    if t.endswith("M"):
        return float(t[:-1]) / 12
    if t.endswith("Y"):
        return float(t[:-1])
    return np.nan


def build_curve_dict(df):
    curves = {}
    for c in df.columns:
        if "_" not in c:
            continue
        fam = c.split("_")[0]
        curves.setdefault(fam, []).append(c)

    out = {}
    for fam, cols in curves.items():
        mats = [tenor_to_years(c) for c in cols]
        valid = [(c, m) for c, m in zip(cols, mats) if not np.isnan(m)]
        if len(valid) >= 3:
            out[fam] = (
                df[[c for c, _ in valid]]
                .rename(columns=dict(valid))  # maturity as float
                .sort_index(axis=1)
            )
    return out


# =========================================================
# PCA ON DAILY RETURNS
# =========================================================

def run_curve_pca_on_returns(df, n_components=5):
    """
    PCA computed on DAILY RETURNS (first difference in bp).
    """
    ret = df.diff().dropna()

    X = ret.values
    mu = X.mean(axis=0)
    Xc = X - mu

    U, S, Vt = np.linalg.svd(Xc, full_matrices=False)
    EV = Vt[:n_components]

    explained = (S**2 / np.sum(S**2))[:n_components].sum()

    return {
        "levels": df.loc[ret.index],
        "returns": ret,
        "columns": df.columns,
        "maturities": np.array(df.columns),
        "eigenvectors": EV,
        "mean": mu,
        "explained_variance": explained,
    }


def reconstruct_returns(model):
    """
    Reconstruct returns using PCA, then cumulate to get implied levels.
    """
    ret = model["returns"]
    EV = model["eigenvectors"]
    mu = model["mean"]

    Xc = ret.values - mu
    scores = Xc @ EV.T
    Xhat = scores @ EV + mu

    ret_hat = pd.DataFrame(Xhat, index=ret.index, columns=ret.columns)
    return ret_hat


# =========================================================
# BACKTEST ENGINE
# =========================================================

def backtest_delta_strategy_swap(
    y_bp,
    z_raw,
    delta_size=10000,
    z_entry=1.5,
    z_exit=0.5,
    hedge_cost_per_bp=0.20,
    ewma_span=20,
):
    df = pd.DataFrame({"y": y_bp, "z_raw": z_raw}).dropna()
    df["z_ewma"] = df["z_raw"].ewm(span=ewma_span, adjust=False).mean()

    pos = 0.0
    last_entry = None
    pos_list = []

    for t in df.index:
        prev = pos
        zE = df.loc[t, "z_ewma"]
        zR = df.loc[t, "z_raw"]

        if abs(zR) <= z_exit:
            pos = 0.0
        else:
            if zE <= -z_entry:
                pos = +delta_size
            elif zE >= z_entry:
                pos = -delta_size

        if prev == 0 and pos != 0:
            last_entry = t

        pos_list.append(pos)

    df["pos"] = pos_list
    df["dy"] = df["y"].diff()
    df["pnl_gross"] = df["pos"].shift(1).fillna(0) * df["dy"]

    df["turnover"] = df["pos"].diff().abs().fillna(df["pos"].abs())
    df["hedge_cost"] = hedge_cost_per_bp * df["turnover"]
    df["pnl_net"] = df["pnl_gross"] - df["hedge_cost"]

    df["pnl_cum_net"] = df["pnl_net"].cumsum()

    sharpe = (
        df["pnl_net"].mean() / (df["pnl_net"].std() + 1e-12) * np.sqrt(252)
    )
    maxdd = (df["pnl_cum_net"] - df["pnl_cum_net"].cummax()).min()

    return {
        "df": df,
        "FinalPnL_net": df["pnl_cum_net"].iloc[-1],
        "Sharpe_net": sharpe,
        "MaxDD_net": maxdd,
        "LastZ": df["z_raw"].iloc[-1],
        "LastEntry": last_entry,
        "LastPos": df["pos"].iloc[-1],
        "HedgeCostCum": df["hedge_cost"].sum(),
    }


def backtest_all_tenors(model, k, roll, ewma_span):
    ret_hat = reconstruct_returns(model)
    ret = model["returns"]
    levels = model["levels"]

    perf = {}
    pnl_curves = {}

    for t in ret.columns:
        resid = ret[t] - ret_hat[t]
        z = (resid - resid.rolling(roll).mean()) / resid.rolling(roll).std()

        bt = backtest_delta_strategy_swap(
            y_bp=levels[t],
            z_raw=z,
            ewma_span=ewma_span,
        )

        perf[t] = bt
        pnl_curves[t] = bt["df"]["pnl_cum_net"]

    perf_df = pd.DataFrame(perf).T
    pnl_curves = pd.DataFrame(pnl_curves)

    return perf_df, pnl_curves


# =========================================================
# STREAMLIT TAB 1
# =========================================================

st.title("Curve PCA on Returns & RV Backtest")

file = st.file_uploader("Upload multi_asset_full.csv", type=["csv"])
if file is None:
    st.stop()

df = pd.read_csv(file)
df["date"] = pd.to_datetime(df["date"], format="%d/%m/%Y", errors="coerce")
df = df.dropna(subset=["date"]).set_index("date").sort_index()

curves = build_curve_dict(df)
curve_name = st.selectbox("Curve", ["EURSWAP", "USDSWAP"])
df_curve = curves[curve_name]

# Date filter
c1, c2 = st.columns(2)
start = c1.date_input("Start", df_curve.index.min().date())
end = c2.date_input("End", df_curve.index.max().date())

df_curve = df_curve.loc[start:end].dropna()

# PCA
model = run_curve_pca_on_returns(df_curve)

st.subheader("PCA Loadings (on returns)")
fig, ax = plt.subplots(figsize=(9, 3))
for i in range(3):
    ax.plot(model["maturities"], model["eigenvectors"][i], label=f"PC{i+1}")
ax.legend()
ax.grid(True)
st.pyplot(fig)

# Backtest params
st.subheader("Backtest parameters")
k = st.slider("PCA factors", 1, 5, 3)
roll = st.slider("Z-score window", 20, 120, 60)
ewma_span = st.slider("EWMA span", 5, 60, 20)

run = st.button("Run backtest")

if run:
    perf_df, pnl_curves = backtest_all_tenors(model, k, roll, ewma_span)

    st.subheader("Performance table")
    st.dataframe(perf_df[[
        "FinalPnL_net", "Sharpe_net", "MaxDD_net",
        "LastZ", "LastEntry", "LastPos", "HedgeCostCum"
    ]].round(3))

    st.subheader("Cumulative Net PnL")
    fig2, ax2 = plt.subplots(figsize=(14, 5))
    ax2.plot(pnl_curves.mean(axis=1), label="Equal-weight portfolio", lw=2.5)
    for c in pnl_curves.columns:
        ax2.plot(pnl_curves[c], alpha=0.3)
    ax2.legend()
    ax2.grid(True)
    st.pyplot(fig2)
