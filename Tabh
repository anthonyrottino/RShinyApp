def backtest_all_tenors_swap_pca(
    data: pd.DataFrame,
    eigenvectors: np.ndarray,
    k: int,
    roll: int,
    delta_size: float,
    z_entry: float,
    z_exit: float,
    hedge_cost_per_bp: float = 0.20,
    use_ewma_signal: bool = True,
    ewma_span: int = 20,
):
    """
    Multi-tenor PCA RV backtest on swap curves.

    ENTRY  : EWMA(z) >= +z_entry  -> SHORT
             EWMA(z) <= -z_entry  -> LONG
    EXIT   : |z_raw| <= z_exit
    PnL    : bp-delta
    COST   : hedge_cost_per_bp * |Î”_change|

    Returns
    -------
    perf_df : DataFrame
        Performance summary per tenor
    pnl_curves_net : DataFrame
        Net cumulative PnL per tenor
    z_last : Series
        Last raw z-score per tenor
    """

    data = data.dropna()
    tenors = data.columns

    # --------------------------------------------------
    # PCA reconstruction (shared across tenors)
    # --------------------------------------------------
    X = data.values
    mu = np.nanmean(X, axis=0)
    Xc = X - mu

    EVk = eigenvectors[:k, :]
    scores = Xc @ EVk.T
    Xhat = scores @ EVk + mu

    yhat = pd.DataFrame(Xhat, index=data.index, columns=tenors)

    perf_rows = []
    pnl_curves_net = {}
    z_last = {}

    # --------------------------------------------------
    # Loop per tenor
    # --------------------------------------------------
    for tenor in tenors:
        y = data[tenor]
        resid = y - yhat[tenor]

        # Raw z-score
        z_raw = (resid - resid.rolling(roll).mean()) / resid.rolling(roll).std()

        # Run backtest (ENTRY on EWMA, EXIT on raw)
        (
            bt,
            last_entry,
            delta_cum,
            last_pos,
            close_t1,
            close_t,
            daily_pnl,
            hedge_cost_cum,
        ) = backtest_delta_strategy_swap(
            y_bp=y,
            z_raw=z_raw,
            delta_size=delta_size,
            z_entry=z_entry,
            z_exit=z_exit,
            hedge_cost_per_bp=hedge_cost_per_bp,
            use_ewma_signal=use_ewma_signal,
            ewma_span=ewma_span,
        )

        # Store net PnL curve
        pnl_curves_net[tenor] = bt["pnl_cum_net"]

        # Metrics
        pnl_net = bt["pnl_net"]
        pnl_cum_net = bt["pnl_cum_net"]

        sharpe_net = (
            pnl_net.mean() / (pnl_net.std() + 1e-12) * np.sqrt(252)
            if pnl_net.std() > 0
            else 0.0
        )

        maxdd_net = float((pnl_cum_net - pnl_cum_net.cummax()).min())

        z_last_val = float(z_raw.dropna().iloc[-1]) if z_raw.dropna().size else np.nan
        z_last[tenor] = z_last_val

        perf_rows.append(
            {
                "Tenor": tenor,
                "FinalPnL_net": float(pnl_cum_net.iloc[-1]),
                "HedgeCostCum": hedge_cost_cum,
                "Sharpe_net": sharpe_net,
                "MaxDD_net": maxdd_net,
                "#Trades": int(bt["trade_flag"].sum()),
                "LastZ_raw": z_last_val,
                "Last entry date": last_entry.date() if last_entry is not None else None,
                "Current position (Î”)": last_pos,
                "Cumulative Î” traded": delta_cum,
                "Close t-1 (bp)": close_t1,
                "Close t (bp)": close_t,
                "DailyPnL (Î”_cum * Î”close)": daily_pnl,
            }
        )

    perf_df = (
        pd.DataFrame(perf_rows)
        .set_index("Tenor")
        .sort_values("Sharpe_net", ascending=False)
    )

    pnl_curves_net = pd.DataFrame(pnl_curves_net)

    return perf_df, pnl_curves_net, pd.Series(z_last)
# =========================================================
# TAB 1 â€“ Curve PCA & RV Backtest (Swap Rates)
# =========================================================

with tab1:
    st.header("1ï¸âƒ£ Curve PCA & RV Backtest (Swap Rates)")

    # -----------------------------------------------------
    # LOAD DATA
    # -----------------------------------------------------
    multi_file = st.file_uploader(
        "Upload multi_asset_full.csv",
        type=["csv"],
        key="multi_asset_file_tab1",
    )

    if multi_file is None:
        st.info("Upload multi_asset_full.csv to run Curve PCA & backtest.")
        st.stop()

    df_multi = pd.read_csv(multi_file)
    df_multi["date"] = pd.to_datetime(
        df_multi["date"], format="%d/%m/%Y", errors="coerce"
    )
    df_multi = (
        df_multi.dropna(subset=["date"])
        .set_index("date")
        .sort_index()
    )

    # -----------------------------------------------------
    # BUILD CURVES (FILTERED)
    # -----------------------------------------------------
    ALLOWED_CURVES = ["EURSWAP", "USDSWAP"]

    curves = build_curve_dict(df_multi)
    curves = {k: v for k, v in curves.items() if k in ALLOWED_CURVES}

    if not curves:
        st.error("No swap curves found (EURSWAP / USDSWAP).")
        st.stop()

    curve_name = st.selectbox("Curve to analyse", sorted(curves.keys()))
    df_curve_full = curves[curve_name]

    st.markdown(f"**Selected curve:** `{curve_name}`")
     
    # -----------------------------------------------------
    # DATE FILTER
    # -----------------------------------------------------
    st.subheader("ðŸ“… Analysis Date Range")

    min_date = df_curve_full.index.min().date()
    max_date = df_curve_full.index.max().date()

    col_d1, col_d2 = st.columns(2)
    with col_d1:
        start_date = st.date_input(
            "Start date",
            value=min_date,
            min_value=min_date,
            max_value=max_date,
        )
    with col_d2:
        end_date = st.date_input(
            "End date",
            value=max_date,
            min_value=min_date,
            max_value=max_date,
        )

    if start_date >= end_date:
        st.error("Start date must be before end date.")
        st.stop()

    df_curve = df_curve_full.loc[start_date:end_date].dropna()

    if len(df_curve) < 80:
        st.warning("Not enough data in selected window.")
        st.stop()

    st.markdown(
        f"Using **{len(df_curve)} obs** from "
        f"**{df_curve.index[0].date()} â†’ {df_curve.index[-1].date()}**"
    )

    # -----------------------------------------------------
    # RUN PCA
    # -----------------------------------------------------
    model = run_curve_pca(df_curve, n_components=5)

    maturities = model["maturities"]
    labels = model["columns"]
    EV = model["eigenvectors"]

    # -----------------------------------------------------
    # PCA LOADINGS
    # -----------------------------------------------------
    st.subheader("PCA Loadings (Level / Slope / Curvature)")

    fig1, ax1 = plt.subplots(figsize=(9, 3))
    for i in range(min(3, EV.shape[0])):
        ax1.plot(maturities, EV[i], marker="o", label=f"PC{i+1}")
    ax1.set_xlabel("Maturity (years)")
    ax1.set_ylabel("Loading")
    ax1.grid(True)
    ax1.legend()
    st.pyplot(fig1)

    # -----------------------------------------------------
    # PCA RECONSTRUCTION (LAST DATE)
    # -----------------------------------------------------
    st.subheader("PCA Reconstruction (Last Date)")

    last_date = df_curve.index[-1]
    table_last, _ = reconstruct_one_date(model, last_date)

    st.dataframe(
        table_last.style.background_gradient(
            cmap="coolwarm", subset=["Residual_z"]
        ),
        use_container_width=True,
    )

    # -----------------------------------------------------
    # BACKTEST PARAMETERS
    # -----------------------------------------------------
    st.subheader("ðŸ“Š RV Backtest â€” All Tenors")

    colp1, colp2, colp3, colp4, colp5 = st.columns(5)
    with colp1:
        k = st.slider("PCA factors (k)", 1, min(5, len(labels)), 3)
    with colp2:
        roll = st.slider("Z-score window", 20, 260, 60)
    with colp3:
        ewma_span = st.slider("EWMA span (signal)", 5, 60, 20)
    with colp4:
        delta_size = st.number_input("Delta size", value=10000, step=1000)
    with colp5:
        z_exit = st.number_input("Exit threshold |z_raw|", value=0.5, step=0.1)

    z_entry = 1.5
    hedge_cost_per_bp = 0.20

    run_bt = st.button("â–¶ Run multi-tenor backtest")

    # -----------------------------------------------------
    # RUN BACKTEST
    # -----------------------------------------------------
    if run_bt:
        data = model["data"].dropna()

        perf_df, pnl_curves, _ = backtest_all_tenors_swap_pca(
            data=data,
            eigenvectors=model["eigenvectors"],
            k=int(k),
            roll=int(roll),
            delta_size=float(delta_size),
            z_entry=float(z_entry),
            z_exit=float(z_exit),
            hedge_cost_per_bp=hedge_cost_per_bp,
            ewma_span=int(ewma_span),          # ENTRY signal
            use_ewma_signal=True,              # ENTRY on EWMA
        )

        # -------------------------------------------------
        # PERFORMANCE TABLE
        # -------------------------------------------------
        st.subheader("ðŸ“‹ Performance Table (per tenor)")

        st.dataframe(
            perf_df.round(3),
            use_container_width=True,
        )

        # -------------------------------------------------
        # PNL CURVES (NET)
        # -------------------------------------------------
        st.subheader("ðŸ“ˆ Cumulative Net PnL")

        pnl_port = pnl_curves.mean(axis=1)

        fig2, ax2 = plt.subplots(figsize=(14, 5))
        ax2.plot(
            pnl_port.index,
            pnl_port.values,
            label="Equal-weight portfolio (net)",
            linewidth=2.5,
        )

        for c in pnl_curves.columns:
            ax2.plot(pnl_curves.index, pnl_curves[c], alpha=0.35)

        ax2.grid(True)
        ax2.legend()
        ax2.set_title(
            f"{curve_name} RV Strategy | "
            f"ENTRY = EWMA(z), EXIT = raw(z)"
        )
        st.pyplot(fig2)

        # -------------------------------------------------
        # Z-SCORE PLOT (SELECTED TENOR)
        # -------------------------------------------------
        st.subheader("ðŸ“‰ Z-Score Signal (Selected Tenor)")

        tenor_sel = st.selectbox(
            "Tenor for signal display",
            list(data.columns),
            index=min(3, len(data.columns) - 1),
        )

        # PCA reconstruction
        X = data.values
        mu = np.nanmean(X, axis=0)
        Xc = X - mu
        EVk = model["eigenvectors"][:int(k), :]
        scores = Xc @ EVk.T
        Xhat = scores @ EVk + mu
        yhat = pd.DataFrame(Xhat, index=data.index, columns=data.columns)

        resid = data[tenor_sel] - yhat[tenor_sel]
        z_raw = (resid - resid.rolling(roll).mean()) / resid.rolling(roll).std()
        z_ewma = z_raw.ewm(span=int(ewma_span), adjust=False).mean()

        figz, axz = plt.subplots(figsize=(14, 4))
        axz.plot(z_raw.index, z_raw, alpha=0.35, label="Raw z-score")
        axz.plot(z_ewma.index, z_ewma, linewidth=2.0, label="EWMA z-score (signal)")

        axz.axhline(+z_entry, color="red", linestyle="--", label="Entry Â±1.5")
        axz.axhline(-z_entry, color="red", linestyle="--")
        axz.axhline(+z_exit, color="orange", linestyle=":", label="Exit Â±0.5")
        axz.axhline(-z_exit, color="orange", linestyle=":")
        axz.axhline(0, color="black", linewidth=0.8)

        axz.set_title(f"{curve_name} â€” {tenor_sel}")
        axz.set_ylabel("z-score")
        axz.grid(True)
        axz.legend()
        st.pyplot(figz)

        # -------------------------------------------------
        # AUTO DESK COMMENT
        # -------------------------------------------------
        last_raw = float(z_raw.dropna().iloc[-1]) if z_raw.dropna().size else np.nan
        last_ewma = float(z_ewma.dropna().iloc[-1]) if z_ewma.dropna().size else np.nan

        st.markdown(
            f"""
**Last signal read**  
â€¢ Raw z-score: **{last_raw:.2f}**  
â€¢ EWMA z-score (entry signal): **{last_ewma:.2f}**

**Interpretation:**  
EWMA smooths noise and reduces false breakouts; exits remain reactive via raw z-score.
"""
        )
